package lang.lexer.debug;

import lang.token.Token;

/**
 * ðŸ“¡ DebugEvent - Token Creation Event ðŸ“¡
 * 
 * Immutable event object containing all information about a token creation.
 * This is the data contract between the lexer and debug system.
 */
public record DebugEvent(
        Token token, // ðŸŽ« The token that was created
        int sourcePosition, // ðŸ“ Position in source where tokenization started
        char triggerChar, // ðŸ”¤ Character that triggered this token
        int endPosition, // ðŸ“ Position where tokenization ended
        long timestamp // â° When this event occurred (nanoseconds)
) {

    /**
     * ðŸ“ Gets the length of the token in source code
     */
    public int getTokenLength() {
        return endPosition - sourcePosition;
    }

    /**
     * ðŸŽ¯ Gets a display-friendly trigger character
     */
    public String getTriggerCharDisplay() {
        return switch (triggerChar) {
            case '\0' -> "EOF";
            case '\n' -> "\\n";
            case '\t' -> "\\t";
            case '\r' -> "\\r";
            case ' ' -> "SPACE";
            default -> String.valueOf(triggerChar);
        };
    }

    /**
     * ðŸ“Š Gets relative timestamp from session start
     */
    public long getRelativeTimestamp(long sessionStartTime) {
        return timestamp - sessionStartTime;
    }
}
